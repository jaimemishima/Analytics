# MapReduce

*******
Tabela de conteúdo 
 1. [MapReduce](#mapreduce)
 2. [MapReduce Job](#mapreducejob)
 3. [Estrutura](#estrutura)
 4. [Hands On](#hands)

*******

<div id='mapreduce'/> 

## MapReduce
Abstração para desenvolvedores de detalhes de paralelismo, load balance e fault tolerance.
- Framework para facilitar e abstrair a execução de aplicações que processam **grande volume de dados** em um **cluster**
- Implementado em Java. Executa programas em Java, Python, Ruby e C++.
- Termos
	- **Job**: programa completo, aplicação.
	- **Tarefa**: execução de um Mapper ou Reducer sobre uma fatia de dados.
- Fluxo
	1. Job submetido ao nó mestre.
	2. Nó mestre se comunica com o NameNode para determinar a localização dos dados.
	3. Nó mestre localiza os nós escravos próximos aos dados.
	4. Nó mestre submete as tarefas aos nós escravos.

### Características
- **Tolerância à falhas**: Recuperação automática de tarefas que falham. Redireciona para outros nós do cluster. Tenta três vezes executar a tarefa. Só depois ele move para outro servidor.
- **Escalabilidade linear**.

<div id='mapreducejob'/> 

## MapReduce Job
Responsabilidade desenvolver:
1. Chaves e valores
	- Base de dados em formato texto.
	- Base de dados deve estar no HDFS.
2. Classe Mapper
	- Recebe uma linha do texto.
	- Tokenização do texto em palavras.
	- Emite para cada palavra um par no formato <palavra, 1>.
3. Classe Reducer
	- Em cada interação, recebe todos os valores de uma chave.
	- Faz a soma dos valores da chave.
	- Emite para cada chave o par <palavra, soma>.
4. Classe Driver
	- Configura o job.
	- Especifica o caminho dos dados de entrada e de saída.
	- Especifica as classes mapper e reducer.
	- Executa o job.

<div id='estrutura'/> 

## Estrutura
Arquitetura mestre escravo
- Mestre: NN (name node, guarda os metadados) e RM (resource manager)
- Escravo: DN (data node) e NM (node manager)

- Resource Manager: central controlling authority for resource management and makes allocation decisions. ResourceManager has two main components: Scheduler and ApplicationsManager. [RM](https://data-flair.training/blogs/hadoop-yarn-resource-manager/)

- Node manager: the per-machine/per-node framework agent who is responsible for containers, monitoring their resource usage and reporting the same to the ResourceManager. NodeManager also tracks the health of the node on which it is running. [NM](https://data-flair.training/blogs/hadoop-yarn-node-manager-tutorial/)

### Função Map
- Par chave/valor gera dados chave/valor intermediários. Não consegue comunicar resultados entre servidores.
- Agrupa os intermediários e transmite para função reduce

### Função Reduce
- Recebe uma chave intermediária um conjunto de valores para essa chave
- Mescla esses valores para formar um conjunto final, consolidando esses valores

### Hadoop Streaming API
Permite executar o mapreduce em diferentes linguagens. Entrada dados recebidas no stdin e saída de dados gravadas no stdout.

<div id='hands'/>

## Hands On

```sh
sudo jps # verificar se os processos estão ativos: NodeManager, ResourceManager 
hdfs dfs -mkdir /user/cloudera/tw2019 # cria diretório
hdfs dfs -put ~/Documents/mensagens.txt /user/cloudera/tw2019 # submete arquivo para o diretório
hdfs dfs -ls tw2019 # verifica se arquivo está no diretório
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount tw2019/mensagens.txt tw2019/saida # execução da aplicação wordcount
hadoop jar ~/Caminho/do/jar/arquivo.jar nomeClasseIniciada dir_dados_entrada dir_dados_saida
hdfs dfs -ls tw2019/saida # visualizar resultado
hdfs dfs -cat tw2019/saida/part-r-00000 # resultado da execução do wordcount
```

Execução aplicação ContadorHashTag
```sh
hadoop jar ~/Documents/LabHadoop.jar com.hadoop.ContadorHashTag tw2019/mensagens.txt tw2019/saida/contador
hdfs dfs -ls tw2019/saida/contador # ver resultado da execução da aplicação
hdfs dfs -text tw2019/saida/contador/part-r-00000 # resultado da execução. -text == -cat.
```

Execução da aplicação TopNHashTag
```sh
hadoop jar ~/Documents/LabHadoop.jar com.hadoop.TopNHashTag tw2019/saida/contador/part-r-00000 tw2019/saida/topn 5 # a base de dados de entrada do job é a base de saída do job anterior.
hdfs dfs -ls tw2019/saida/topn
hdfs dfs -text tw2019/saida/topn/part-r-00000
```

Salvar arquivo do hdfs para a maquina local
```sh
hdfs dfs -ls tw2019/saida/topn
hdfs dfs -get tw2019/saida/topn/part-r-00000 /home/cloudera/Documents/saidaTopN.txt
```

Criar um novo diretório no HDFS
```sh
hdfs dfs -mkdir /user/cloudera/resultados
hdfs dfs -cp tw2019/saida /user/cloudera/resultados
```


