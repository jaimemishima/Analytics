# Ecossistema Hadoop e YARN

*******
Tabela de conteúdo 
 1. [Contexto](#contexto)
 2. [Ecossistema Hadoop](#ecossystem)
 3. [YARN](#yarn)
 4. [Casos de Uso](#usecases)


*******

<div id='contexto'/> 

## Contexto
Um sistema operacional para Big Data. Foram criadas novas tecnologias e técnicas para facilitar o processamento dos dados.

<div id='ecossystem'/> 

## Ecossistema Hadoop
### Sqoop (SQL to Hadoop)
- Importa tabelas de bancos de dados relacionais para o Hadoop e vice-versa. 
- Internamente usa o map reduce jobs para fazer a transferência. 
- Baseado em conectores para entender os metadados para o sistema Hadoop.

### ZooKeeper
- **Coordenação de processos** de aplicações distribuídas. Visão das informações dos nós mestre-escravos. 
- Solução geral para **não ter um coordenador específico para cadas solução** do ecossistema. 
- Oferece alta disponibilidade, uso de namenode ativo e standby com 3 processos (journalnode) que guarda operações.
- **Não usar com o secondary name node** pois eles concorrem em processos.

### HBase
- Para fazer a leitura e escrita rápida dos dados. 
- É o **NoSQL colunar** do Hadoop. (4 tipos: chave-valor, documentos, colunas e grafos). 
- Foi **baseado numa solução do Google Big Table**, faz a leitura e escrita de tabelas gigantescas. 
- Faz o acesso aleatório em tabelas esparsas (flexibilidade de colunas). 
- Os dados continuam sendo armazenados em arquivos no HDFS. Ele é uma camada acima para facilitar o acesso e fornecer uma baixa latência.
- Muito utilizado para fazer update de dados.
- **Cassandra** é o **principal concorrente** do HBase.
- Exemplos de casos de uso:
	- *Meetup.com*: armazena diretamente no HBase, indexado por membro, feed personalizado gerado no HBase.
	- *Twitter*: backup distribuído das tabelas do MySQL.
	- *Facebook*: armazenamento do sistema de mensagens em tempo real.
- Restrições: a API é bem restrita, não utiliza o SQL.

### Pig
- Linguagem de mais alto nível para o desenvolvimento de aplicações map reduce. 
- **Formato de script para manipulação de dados: PigLatin**. Oferece operações padrões (filter, join, groupby, orderby...). 
- Contexto de pipeline para lidar com dados não estruturados e tem operações para fazer a preparação dos dados.

### Hive
- Executar operações de analytics sobre os dados armazenados. **Linguagem HiveQL**, gera MapReduce e SparkJobs. Desenvolvido pelo Facebook. Data warehouse do Hadoop. 
- Projetado para **OLAP** (Online Analytical Processing, em blocos) não OLTP (de baixa latência, solução é o Inpala).
- Projetado para **dados estruturados ou semi-estruturados**.

### Flume
- Voltado para **coleta e ingestão de dados a partir de diferentes fontes** para o Hadoop. 
- Contexto baseado em agentes para capturar informações de arquivos de log em servidores. 
	- Fica escutando uma porta/diretório. 
	- A partir do momento que identifica uma alteração ele captura os dados. 
- Exemplos de usos em **aplicações de IoT** (gera o dado e remove do ambiente limitado) e **detecção de fraude**.
- Definir onde ficam armazenados os dados temporários e o sync para envio dos dados para o destino final.
- Aplicações:
	- Coleta de dados em tempo real e em lote
	- Permite conexão com APIs de redes sociais (Facebook e Twitter).

### Kafka
- Controle de entrada de mensagens e execução de **consumo dos dados em tempo real**. 
- Plataforma de streaming de dados, tem funcionalidades para definir fluxos de dados: processamento de dados e armazenamento. 
- Não necessita necessariamente do Hadoop. Mas está cada vez mais acoplado ao ecossistema. Nasceu dentro do Linkedin.
- Uso pela Globo para o sistema de recomendação. Sistema de ecommerce para tratamento de eventos em tempo real (OLX).
- Case [Netflix](https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a).


<div id='yarn'/> 

## YARN (Yet Another Resource Negotiator)
- Diferenças entre Hadoop 1.x para 2.x:
	- Divisão das duas funções do JobTracker
	- Gerenciamento de recursos
	- Gerenciamento de jobs
	- MapReduce é uma aplicação do Hadoop
	- Remoção de slots fixos

- YARN é responsável por:
	- Gerenciamento de recursos do cluster
	- Alocação de recursos
	- Controles de segurança
	- Monitoramento de cargas de trabalho
	- Operações de administradores
	- Escalonamento de tarefas

- **Estrutura**
	- **Aplicação**: um job submetido ao Hadoop (ex. MapReduce job)
	- **Container**: unidade de alocação de recursos (ex.: c1 = 1 GB, 2 CPU) substitui os slots fixados das tarefas map e reduce
	- **Resource Manager**: escalonador global de recursos. Ponto único de falha, se falhar o cluster fica indisponível até ser iniciado.
		- **Resource Manager High Availability** (RM HA): 
			- Permite RMs redundantes.
			- Arquitetura Active/Standby.
			- Zookeeper determina qual RM permanece ativo.
	- **Node Manager**: gerencia o ciclo de vida do container, monitora os recursos do container (1 por máquina)
	- **Application Master**: gerencia a execução e escalonamento das tarefas (1 por aplicação)

- Fluxo de execução
	1. Um cliente submete uma **aplicação** (job) para o **Resource Manager**
	2. O **Resource Manager** aloca um **Container**
	3. O **Resource Manager** faz contato com o **Node Manager**
	4. O **Node Manager** inicia o **Container**
	5. O **Container** executa a **Application Master**


<div id='yarn'/> 

## Casos de Uso
- [Pirelli](https://pt.slideshare.net/carlotorniai/how-a-global-manufacturing-company-built-a-data-science-capability-from-scratch)
- [Globo.com](https://cirocavani.github.io/post/bigdata-na-globocom/)
- [Uber](https://eng.uber.com/uber-big-data-platform/)
- [Magazine Luiza](https://pt.slideshare.net/imasters/devcommerce-conference-2016-workshop-busca-e-data-lake-analytics)
