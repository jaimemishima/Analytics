# Introdução ao Hadoop

*******
Tabelas de conteúdo 
 1. [Motivação](#motivation)
 2. [O que é Big Data?](#whatis)
 3. [História Hadoop](#history)
 4. [Características Hadoop](#caracteristics)
 5. [Modos Execução](#execution)
 6. [HDFS](#hdfs)
 7. [Hands On](#hands)

*******

<div id='motivation'/> 

## Motivação
- Processamento Tradicional
	- [x] Escalabilidade vertical via aumento de recursos em uma única máquina.
	- [ ] Problemas de custo, desempenho e escalabilidade limitada.
- Processamento em Larga Escala
	- [x] Escalabilidade horizontal via adição de máquinas no cluster.
	- [ ] Problemas: Adaptação de tecnologias e aumento de complexidade.
- **Redução de custo**: cluster heterogêneo permite diferentes marcas e especificações, open source. Alta disponibilidade e tolerância a falhas, escalabilidade e desempenho.
- **Flexibilidade**: dados de geolocalização, RFID, vídeo e áudio.
- **Schema on write**: permite armazenar o dado na forma bruta.
- **Escalabilidade**: facilidade de adicionar novos servidores ao cluster. O código é o mesmo para 2 ou 100 máquinas.
- **Novas Análises**: desenvolver modelos sem usar amostras de dados.
- **Ecossistema de soluções**: subprojetos para atender diferentes necessidades.

<div id='whatis'/> 

## O que é Big Data?
Segundo a Professora [Rosangela Marquesone](www.linkedin.com/in/rosangelafpm):
>*Novas tecnologias capazes de oferecer escalabilidade, disponibilidade, flexibilidade e desempenho para a manipulação de grande volume de dados*

<div id='history'/>

## História Hadoop
### Apache Nutch
	- Projeto open source para motor de busca, escalabilidade limitada.
	- Baseado em dois artigos do Google: Google File System e MapReduce.
	- Permite sistema distribuído e melhoria de escalabilidade.

### Yahoo
	- Desafio de indexar a web. Sistema distribuído do Nutch se torna um projeto independente e se chama Hadoop.

<div id='caracteristics'/>

## Características Hadoop
	- Framework open source para executar aplicações com milhares de máquinas.
	- Recursos de armazenamento, gerenciamento e processamento distribuído de dados.
	- Processamento em lote

<div id='execution'/>

## Modos de Execução
	- Local (standalone): debugar código.
	- Pseudo-distribuído: executados em uma única máquina.
	- Completamente distribuído: cluster múltiplas máquinas.

<div id='hdfs'/>

## HDFS
- Sigla para **H**adoop **D**istributed **F**ile **S**ystem
	- Sistema de arquivos distribuído.
	- Executado em sistema de arquivos distribuído.
	- Alta taxa de transferência.
	- Abstração do funcionamento.
	- Escalável e tolerante à falhas.
	- *Write onde, read many*.
- 3 processos principais:
	- **NameNode**: Gerencia o namespace do sistema de arquivos.
	- **DataNode**: Armazena os blocos de dados em um nó.
	- **SecondaryNameNode**: Tarefas de ponto de verificação e manutenção do NameNode.
- Arquivos divididos em blocos de 128Mb
- Blocos replicados para tolerância à falhas: 3 réplicas

<div id='hands'/>

## Hands On
Hadoop é open source com uma base de [distribuição pública](https://hadoop.apache.org/)

Verificando o local do Hadoop
```sh
$ cd /usr/lib/hadoop
$ ls
```

Verificando a estrutura do Hadoop
```sh
$ cd /usr/lib/hadoop/etc/hadoop
$ ls
```

Verificando processos ativso do Hadoop
```sh
$ sudo jps
$ sudo service hadoop-hdfs-namenode status
$ sudo service hadoop-hdfs-datanode status
$ sudo service hadoop-hdfs-secondarynamenode status
```

Criar um diretório no Hadoop
```sh
$ hdfs dfs -mkdir /user/cloudera/bases2019
$ hdfs dfs -ls
```

Enviar base para o HDFS
```sh
$ hdfs dfs -put ~/Documents/vendas.txt /user/cloudera/bases2019
$ hdfs dfs -ls bases2019
```

Visualizando o conteúdo do último kbyte do arquivo no HDFS
```sh
$ hdfs dfs -tail bases2019/vendas.txt
```

Enviar base do HDFS para máquina local
```sh
$ hdfs dfs -get bases2019/vendas.txt /home/cloudera/Documents/vendas_backup.txt
$ ls ~/Documents/
```

Copiando o arquivo para outro diretório do HDFS
```sh
$ hdfs dfs -mkdir /user/cloudera/bases2020
$ hdfs dfs -cp bases2019/vendas.txt bases2020
$ hdfs dfs -ls bases2020
```

Remover arquivo e diretório do HDFS
```sh
$ hdfs dfs -rm bases2020/vendas.txt # remove arquivo
$ hdfs dfs -rm -r bases2020 # remove diretorio
```

Balanceamento do HDFS
```sh
$ hdfs balancer
```


