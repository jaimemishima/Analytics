# Hive

*******
Tabela de conteúdo 
 1. [Cenários](#scenario)
 2. [O que é?](#whatisit)
 3. [Arquitetura](#architecture)
 4. [Terminologia](#terminology)
 5. [Benefícios](#benefits)
 6. [Limitações](#limitations)
 7. [Formatos de Armazenamento](#formats)


*******

<div id='scenario'/> 

## Cenários
- Executar tarefas em lote em um ETL muito grande com joins e sorts.
- Jobs de transferência ou conversão de dados que levam muitas horas.
- Dados em diferentes formatos.


<div id='whatisit'/> 

## O que é?
- Framework para soluções de datawarehouse no Hadoop.
- Para dados estruturados e semi-estruturados de larga escala.
- Schema on read. Faz a transformação após os dados serem carregados.
- Linguagem de alto nível: HiveQL.
- Interpreta instruções SQL para MapReduce.
- Não foi projetado para ter baixa latência (não roda em milisegundos) pois o processamento é em lote.

<div id='architecture'/>

## Arquitetura
	1. Hive Metastore
		- Armazena os metadados do Hive em um banco de dados relacional.
		- Acesso aos clientes via API.
	2. Compilador de Query e engine de execução
		- Query submetida ao driver
		- O compilador analisa a sintaxe da query
		- O compilador solicita metadados para o metastore
		- O Metastore envia os metadados
		- O compilador analisa o plano de execução e retorna ao driver
		- O job é executado no Hadoop
		- A engine de execução recebe o resultado
	3. SerDe (Serializer and Deserializer)
		- Define o schema da tabela.
		- Para ler e escrever nas tabelas Hive.
	4. Categorias de Funções
		- UDF (User defined function): map um-para-um
		- UDAF (User Defined Aggregated Function): map muitos para um
		- UDTF (User Defined Table-generated Function): map um para muitos

<div id='terminology'/>

## Terminologias
- **Database**: coleção de tabelas Hive
- **Tabela**: mapeamento para um diretório no HDFS
	- **Internas**: armazenados no dw. Faz ligação física com dados no HDFS. Se der drop, os dados são excluídos. Hive gerencia o ciclo de vida das tabelas.
	- **Externa**: dados fora do dw. Para dados usados fora do Hive. Ou dados manipulados por outra solução que não seja o Hive.
	- **Temporária**: somente durante a sessão do usuário.
- **Partições**: divisões nas tabelas em valores distintos de colunas. Subdiretórios.
	- Evita a leitura de todos os dados no diretório. 
	- As entradas para as várias colunas do conjunto de dados são segregadas e armazenadas em suas respectivas partições.

- **Bucket**: funções hash para definir quais dados são armazenados em um mesmo arquivo.
	- Partition permite o scan de somente uma partição de dados.
	- Mas se o conjunto de dados for grande, o tamanho do arquivo pode continuar grande.
	- Divide o conjunto de dados da tabela em partes mais gerenciáveis.
	- Ideia: função hash define para qual arquivo um registro é enviado:
		- CLUSTERED BY divide a tabela em buckets.
	- Vantagens: eficiência na amostragem de dados, facilidade na depuração.

- Partition vs Bucket:
	- Partition: partição é um diretório
	- Bucket: bucket é um arquivo

<div id='benefits'/>

## Benefícios
- Familiaridade com a linguagem SQL.
- Rapidez para datasets imensos. Em segundo, mas não ms.
- Escalável e extensível.
- Compatível: integração com diversas soluções de BI (Tableau, Power BI...)

<div id='limitations'/>

## Limitações
- Não projetado para OLTP. Somente OLAP (online analytical process).
- Não é um banco de dados completo, não é relacional.
- Não indicado para base de dados pequenas. Devido a quantidade de bytes por bloco.

<div id='formats'/>

## Formatos de Armazenamento
	1. Row Format
		- SerDe encapsula a lógica para converter os bytes não estruturados em um registro.
	2. File Format
		- Como os registros são armazenados dentro do arquivo.
			1. TextFile: padrão
			2. SequenceFile
				- Arquivo sequencial: armazena registros em sequência e é orientado a linha.
				- Mesclar arquivos pequenos em um arquivo maior.
				- Processado mais rapidamente que o formato TextFile.
			3. RCFile (Record Columnar File)
				- Armazenamento orientado a colunas.
				- Particiona linhas horizontalmente em divisões (spits) de linha e depois verticalmente cada divisão de maneira colunar.
				- Vantagens: rápido carregamento de dados, processamento de quey e uso eficiente de espaço de armazenamento.
				- Desvantagens: gravação consome mais memória e processamento.
			4. ORCFile (Optimized Row Columnar)
				- Reduz tamanho dos dados em até 75%.
				- Melhora desempenho na leitura, gravação e processamento de dados.
				- Utilizado em conjunto com o spark.
				- Vantagens: 
					- Geração de um único arquivo de tarefa.
					- Permitiu formato com tipos de dados complexos (struct, list, map...)
					- Construção bloco a bloco.
					- Leituras simultâneas ao arquivo.
					- Limita quantidade de memória na leitura e escrita.
					- Permite alteração da estrutura da tabela: adição/remoção de campos.
			5. Parquet
				- Desenvolvido na Cloudera em parceria com o Twitter.
				- Baseado no formato de arquivo Dremel ColumnIO.
				- Schema similar ao Protocol Buffers.
				- Utilizado em conjunto com Hive e Impala
				- Interage com outras soluções do ecossistema Hadoop.
			6. Avro File
				- Projeto que oferece serviço de serialização de dados para o Hadoop.
				- Permite trocar dados entre o ecossistema Hadoop e o programa escrito em qualquer linguagem de programação.
				- Mantém metadados a nível de arquivo, não registro.
				- Formato binário. Utiliza json.
			7. Custom IF/OF
				- Criação de classes Hive InputFormat e Record Reader personalizadas.
			8. Codec (compression - decompression)
				- Adicionar algoritmo de compressão de dados.
				- Custo computacional maior para leitura/escrita de dados.






